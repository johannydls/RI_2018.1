{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperação da Informação e Busca na Web - 2018.1\n",
    "\n",
    "### Atividade: Lab 01 - Parte 2 - Ranking e Modelo Vetorial\n",
    "### Aluno: Johanny de Lucena Santos\n",
    "\n",
    "## - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações necessárias para a análise dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo download de biblioteca necessária para realizar a tokenização das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JohannyLS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Definindo o arquivo com os dados a ser analisado e o gabarito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/estadao_noticias_eleicao.csv', sep=',')\n",
    "\n",
    "#Substituindo linhas com valores NaN por string vazia, para não atrapalhar nas operações\n",
    "dataset = dataset.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento do Gabarito\n",
    " Usando a biblioteca **Abstract Syntax Trees** (ast) para converter as strings do gabarito para o objeto lista, junto com a função apply() da biblioteca **Pandas** para aplicar a conversão em todas as linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gabarito = pd.read_csv('../data/gabarito.csv')\n",
    "\n",
    "gabarito['google']        = gabarito['google'].apply(ast.literal_eval)\n",
    "gabarito['busca_binaria'] = gabarito['busca_binaria'].apply(ast.literal_eval)\n",
    "gabarito['tf']            = gabarito['tf'].apply(ast.literal_eval)\n",
    "gabarito['tfidf']         = gabarito['tfidf'].apply(ast.literal_eval)\n",
    "gabarito['bm25']          = gabarito['bm25'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções para avaliação das saídas utilizando a métrica Mean Average Precision (MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para remover acentuação das palavras dos documentos\n",
    "Módulo **re** e **unicodedata** necessários para tratamento de expressões regulares e normalização de string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_acentuacao(palavra):\n",
    "    pattern = re.compile('[^a-zA-Z0-9 ]')\n",
    "    texto = normalize('NFKD', palavra).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    return pattern.sub(' ', palavra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando junção dos títulos, subtítulos e conteúdos\n",
    "Na junção, está sendo removidos todos os acentos para facilitar a criação dos tokens dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos = dataset.titulo + \" \" + dataset.subTitulo + \" \" + dataset.conteudo\n",
    "documentos = documentos.apply(lambda palavra: remove_acentuacao(palavra).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação dos docIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docIDs = dataset.idNoticia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando os tokens dos dados e a frequência de termos de cada documento da lista de postings\n",
    "Utilizando a função **Count** da biblioteca **Collections** para realizar a contagem dos termos (frequência)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = documentos.apply(nltk.word_tokenize)\n",
    "termo_frequency = tokens.apply(Counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função geradora do índice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiceInvertido = {}\n",
    "\n",
    "def gerarIndiceInvertido():\n",
    "    for i in range(len(tokens)):\n",
    "        idNoticia = docIDs[i]\n",
    "        palavras = tokens[i]\n",
    "    \n",
    "        for palavra in palavras:\n",
    "            if palavra not in indiceInvertido:\n",
    "                indiceInvertido[palavra] = {}\n",
    "        \n",
    "            if not indiceInvertido[palavra].get(idNoticia):\n",
    "                docs = indiceInvertido[palavra]\n",
    "                docs[idNoticia] = tf[i][palavra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerarIndiceInvertido()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para retornar as palavras mais proximas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_aproximada(termo, qtd):\n",
    "    termos = indiceInvertido.keys()\n",
    "    return sorted(termos, key=lambda palavra: nltk.edit_distance(termo,palavra))[0:qtd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para gerar um dicionário com os pesos dos índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dict_pesos(frase, gerador_peso):\n",
    "    termos = frase.split(\" \")\n",
    "    docs_peso = {}\n",
    "    \n",
    "    for i in range(len(termos)):\n",
    "        termo = termos[i]\n",
    "        docs = indiceInvertido[termo]\n",
    "        \n",
    "        for doc_id in docs:\n",
    "            tf = docs[doc_id]\n",
    "            \n",
    "            if doc_id not in docs_peso:\n",
    "                docs_peso[doc_id] = np.array([0 if j != i else gerador_peso(tf) for j in range(len(termos))])\n",
    "            else:\n",
    "                doc_vector = docs_peso[doc_id]\n",
    "                docs_peso[doc_id] = np.array([doc_vector[j] if j != i else gerador_peso(tf) for j in range(len(termos))])\n",
    "    \n",
    "    return docs_peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para gerar um dicionário com vetores binários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_binario(frase):\n",
    "    def gerador_peso(tf):\n",
    "        return 1\n",
    "    return gerar_dict_pesos(frase, gerador_peso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para gerar o TF da consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_vetor_tf(frase):\n",
    "    def gerador_peso(tf):\n",
    "        return tf\n",
    "    return gerar_dict_pesos(frase, gerador_peso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para gerar IDF dos termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_vetor_tfidf(frase):\n",
    "    termos = frase.split(\" \")\n",
    "    vetor_tfidf = np.array([math.log((len(documentos)+1)/len(indiceInvertido[termo])) for termo in termos])\n",
    "    return vetor_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para gerar o vetor binário de consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_consulta(frase):\n",
    "    termos = frase.split(\" \")\n",
    "    vetor = np.array([1 if indiceInvertido.get(termo) else 0 for termo in termos])\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para gerar um dicionário com vetores BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_vetor_bm25(frase):\n",
    "    docs_tf = gerar_vetor_tf(frase)\n",
    "    k = 5\n",
    "    vetor_bm25 = {doc_id: np.array([((k+1)*tf)/(tf+k) for tf in vetor_tf]) for doc_id, vetor_tf in docs_tf.items()}\n",
    "    \n",
    "    return vetor_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de busca binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_binaria(frase):\n",
    "    docs_tf = gerar_binario(frase)\n",
    "    consulta = gerar_consulta(frase)\n",
    "    doc_rank = sorted(list(docs_tf.items()), key=lambda doc: np.dot(doc[1], consulta), reverse=True)[:5] \n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de busca por TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_tf(frase):\n",
    "    docs_tf = gerar_vetor_tf(frase)\n",
    "    query = gerar_consulta(frase)\n",
    "    doc_rank = sorted(list(docs_tf.items()), key=lambda doc: np.dot(doc[1], query), reverse=True)[:5] \n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de busca por TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_tf_idf(frase):\n",
    "    doc_tf = gerar_vetor_tf(frase)\n",
    "    doc_idf = gerar_vetor_tfidf(frase)\n",
    "    doc_rank = sorted(list(doc_tf.items()), key=lambda doc: np.dot(doc[1], doc_idf), reverse=True)[:5]\n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de busca por BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_bm25(frase):\n",
    "    doc_bm25 = gerar_vetor_bm25(frase)\n",
    "    query = gerar_consulta(frase)\n",
    "    doc_rank = sorted(list(doc_bm25.items()), key=lambda doc: np.dot(doc[1], query), reverse=True)[:5]\n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realizando avaliações através da Mean Average Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação da precisão da busca binária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local  = 0.2400\n",
      "Google = 0.0400\n"
     ]
    }
   ],
   "source": [
    "busca_bin  = [busca_binaria(remove_acentuacao(frase)) for frase in gabarito.str_busca]\n",
    "\n",
    "print(\"Local  = %.4f\" %(mapk(gabarito.busca_binaria, busca_bin, k=5)))\n",
    "print(\"Google = %.4f\" %(mapk(gabarito.google, busca_bin, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação da precisão da busca por TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local  = 0.6040\n",
      "Google = 0.0480\n"
     ]
    }
   ],
   "source": [
    "busca_term_freq = [busca_tf(remove_acentuacao(frase)) for frase in gabarito.str_busca]\n",
    "\n",
    "print(\"Local  = %.4f\" %(mapk(gabarito.tf, busca_term_freq, k=5)))\n",
    "print(\"Google = %.4f\" %(mapk(gabarito.google, busca_term_freq, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação da precisão da busca por TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local  = 0.5920\n",
      "Google = 0.0600\n"
     ]
    }
   ],
   "source": [
    "busca_tfidf  = [busca_tf_idf(remove_acentuacao(frase)) for frase in gabarito.str_busca]\n",
    "print(\"Local  = %.4f\" %(mapk(gabarito.tfidf, busca_tfidf, k=5)))\n",
    "print(\"Google = %.4f\" %(mapk(gabarito.google, busca_tfidf, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca: 'segundo turno'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busca Binária   : [1, 7, 13, 26, 69]\n",
      "Busca por TF    : [2744, 7, 2112, 7672, 2388]\n",
      "Busca por TF IDF: [2744, 2112, 7672, 1235, 2388]\n",
      "Busca por BM25  : [2744, 2112, 7672, 2388, 2178]\n"
     ]
    }
   ],
   "source": [
    "print(\"Busca Binária   :\", busca_binaria('segundo turno'))\n",
    "print(\"Busca por TF    :\", busca_tf('segundo turno'))\n",
    "print(\"Busca por TF IDF:\", busca_tf_idf('segundo turno'))\n",
    "print(\"Busca por BM25  :\", busca_bm25('segundo turno'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca: 'lava jato'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busca Binária   : [3, 13, 15, 27, 43]\n",
      "Busca por TF    : [163, 353, 6942, 2807, 127]\n",
      "Busca por TF IDF: [163, 353, 6942, 2807, 127]\n",
      "Busca por BM25  : [163, 353, 6942, 2807, 127]\n"
     ]
    }
   ],
   "source": [
    "print(\"Busca Binária   :\", busca_binaria('lava jato'))\n",
    "print(\"Busca por TF    :\", busca_tf('lava jato'))\n",
    "print(\"Busca por TF IDF:\", busca_tf_idf('lava jato'))\n",
    "print(\"Busca por BM25  :\", busca_bm25('lava jato'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca: 'projeto de lei'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busca Binária   : [7, 10, 25, 38, 56]\n",
      "Busca por TF    : [7, 155, 6554, 3942, 7017]\n",
      "Busca por TF IDF: [7017, 5129, 6096, 2853, 155]\n",
      "Busca por BM25  : [2853, 7017, 2232, 3171, 6461]\n"
     ]
    }
   ],
   "source": [
    "print(\"Busca Binária   :\", busca_binaria('projeto de lei'))\n",
    "print(\"Busca por TF    :\", busca_tf('projeto de lei'))\n",
    "print(\"Busca por TF IDF:\", busca_tf_idf('projeto de lei'))\n",
    "print(\"Busca por BM25  :\", busca_bm25('projeto de lei'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca: 'compra de voto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busca Binária   : [82, 347, 553, 748, 854]\n",
      "Busca por TF    : [7, 155, 6554, 3942, 7017]\n",
      "Busca por TF IDF: [173, 2047, 7017, 7343, 7]\n",
      "Busca por BM25  : [2047, 2178, 7017, 2200, 7343]\n"
     ]
    }
   ],
   "source": [
    "print(\"Busca Binária   :\", busca_binaria('compra de voto'))\n",
    "print(\"Busca por TF    :\", busca_tf('compra de voto'))\n",
    "print(\"Busca por TF IDF:\", busca_tf_idf('compra de voto'))\n",
    "print(\"Busca por BM25  :\", busca_bm25('compra de voto'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Busca: 'ministério público'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Busca Binária   : [578, 845, 847, 874, 1069]\n",
      "Busca por TF    : [7, 155, 6554, 3942, 7017]\n",
      "Busca por TF IDF: [173, 2047, 7017, 7343, 7]\n",
      "Busca por BM25  : [2047, 2178, 7017, 2200, 7343]\n"
     ]
    }
   ],
   "source": [
    "print(\"Busca Binária   :\", busca_binaria('publico'))\n",
    "print(\"Busca por TF    :\", busca_tf('compra de voto'))\n",
    "print(\"Busca por TF IDF:\", busca_tf_idf('compra de voto'))\n",
    "print(\"Busca por BM25  :\", busca_bm25('compra de voto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ministerial', 'ministeriais', 'ministeri', 'interrompido', 'ministrou', 'ministro', 'interioriza', 'ministros', 'interrompendo', 'interrompida']\n"
     ]
    }
   ],
   "source": [
    "print(busca_aproximada('ministerio publico',10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
