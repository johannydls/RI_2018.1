{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperação da Informação e Busca na Web - 2018.1\n",
    "\n",
    "### Atividade: Lab 02 - Parte 1 - Expansão de Consultas\n",
    "### Aluno: Johanny de Lucena Santos\n",
    "\n",
    "## - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "\n",
    "Nesta atividade você vai exercitar a noção de expansão de consultas. Considerando a coleção de notícias do lab passado, você primeiro precisa executar os seguintes passos:\n",
    "\n",
    "1. Escreva uma função que receba uma coleção de documentos e retorne uma matrix de termos-termos contendo as frequências de co-ocorrência de duas palavras consecutivas no texto (bigramas).\n",
    "2. Escreva uma função que receba um certo termo de consulta e a matriz construída no passo 1 acima e retorneas top-3 palavras em ordem decrescente de frequencia.\n",
    "3. Expanda a consulta original com os termos retornados no passo 2 acima.\n",
    "4. Faça uma busca disjuntiva (OR) considerando a nova consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações necessárias para a análise dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Definindo o arquivo com os dados a ser analisado\n",
    "Esse é o arquivo base de estudo, que contém notícias de um determinado período de tempo relacionados à eleições, da base de notícias do Estadão.\n",
    "\n",
    "Primeiramente, fazemos a importação do arquivo no formato .csv para tratamento, e em seguida, removemos as linhas com valores NaN (not a number) para não atrapalhar nas operações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/estadao_noticias_eleicao.csv', encoding=\"utf-8\")\n",
    "dataset = dataset.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join dos conteúdos\n",
    "\n",
    "Realizando junção dos títulos, subtítulos e conteúdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentos = dataset.titulo + \" \" + dataset.subTitulo + \" \" + dataset.conteudo\n",
    "documentos = documentos.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação dos docIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docIDs = dataset.idNoticia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que gera uma matriz de co-occorrência e vocabulário\n",
    "\n",
    "Essa função recebe o corpus (documentos) e retorna uma matriz termos-termos contendo as frequências de co-ocorrência de duas palavras consecutivas no texto (bigramas), bem como o vocabulário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo pontuação\n",
    "As pontuações estão sendo removidas para que a tokenização seja feita apenas com as palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens_lists = documentos.apply(lambda text: tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removendo stopwords\n",
    "Removendo as palavras que podem ser consideradas irrelevantes para o conjunto de resultados a ser exibido em uma busca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ = stopwords.words('portuguese')\n",
    "filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando lista de tokens e matriz de co-ocorrência e vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for tokens_list in filtered_tokens for token in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, vocab = co_occurrence_matrix(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequência de termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequency = tokens_lists.apply(Counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando índice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indiceInvertido = {}\n",
    "\n",
    "def gerarIndiceInvertido():\n",
    "    for i in range(len(tokens_lists)):\n",
    "        idNoticia = docIDs[i]\n",
    "        palavras = tokens_lists[i]\n",
    "    \n",
    "        for palavra in palavras:\n",
    "            if palavra not in indiceInvertido:\n",
    "                indiceInvertido[palavra.lower()] = {}\n",
    "        \n",
    "            if not indiceInvertido[palavra.lower()].get(idNoticia):\n",
    "                docs = indiceInvertido[palavra.lower()]\n",
    "                docs[idNoticia] = term_frequency[i][palavra.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerarIndiceInvertido()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para gerar um dicionário com os pesos dos índices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_dict_pesos(termos, gerador_peso):\n",
    "\n",
    "    docs_peso = {}\n",
    "    \n",
    "    for i in range(len(termos)):\n",
    "        termo = termos[i].lower()\n",
    "        docs = indiceInvertido[termo]\n",
    "        \n",
    "        for doc_id in docs:\n",
    "            tf = docs[doc_id]\n",
    "            \n",
    "            if doc_id not in docs_peso:\n",
    "                docs_peso[doc_id] = np.array([0 if j != i else gerador_peso(tf) for j in range(len(termos))])\n",
    "            else:\n",
    "                doc_vector = docs_peso[doc_id]\n",
    "                docs_peso[doc_id] = np.array([doc_vector[j] if j != i else gerador_peso(tf) for j in range(len(termos))])\n",
    "    \n",
    "    return docs_peso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para gerar o vetor de consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_consulta(termos):\n",
    "    vetor = np.array([1 if indiceInvertido.get(termo.lower()) else 0 for termo in termos])\n",
    "    return vetor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para gerar o TF da consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_vetor_tf(frase):\n",
    "    def gerador_peso(tf):\n",
    "        return tf\n",
    "    return gerar_dict_pesos(frase, gerador_peso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de busca por TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_tf(frase):\n",
    "    docs_tf = gerar_vetor_tf(frase)\n",
    "    query = gerar_consulta(frase)\n",
    "    doc_rank = sorted(list(docs_tf.items()), key=lambda doc: np.dot(doc[1], query), reverse=True)\n",
    "    return [doc[0] for doc in doc_rank]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de busca disjuntiva (OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_or(*termos):\n",
    "    uniao = set(indiceInvertido[termos[0].lower()])\n",
    "    for termo in termos:\n",
    "        ids = set(indiceInvertido[termo.lower()])\n",
    "        uniao = uniao.union(ids)\n",
    "    return list(uniao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação de uma matriz consultável com base na matriz de co-ocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultable_matrix = matrix.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função que retorna a frequência entre duas palavras\n",
    "Retorna a frequência entre duas palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_frequency(w1, w2):\n",
    "    return(consultable_matrix[vocab[w1],vocab[w2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "## Função que retorna as top 3 palavras da consulta\n",
    "\n",
    "Esta função recebe um certo termo para consultar com base na matriz construída (consultable_matrix) anteriormente e retorneas top-3 palavras em ordem decrescente de frequência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_words(termo):\n",
    "    ranking = consultable_matrix[vocab[termo]].getrow(0).toarray()[0]\n",
    "    indices, freq = zip(*sorted(enumerate(ranking), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    return indices[:3], ranking[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_words_txt(termo):\n",
    "    ranking = consultable_matrix[vocab[termo]].getrow(0).toarray()[0]\n",
    "    indices, freq = zip(*sorted(enumerate(ranking), key=lambda x: x[1], reverse=True))\n",
    "    \n",
    "    return ([p for key in indices[:3] for p in vocab.keys() if vocab[p] == key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de busca expandida\n",
    "Expansão da consulta original com os termos retornados na função **top_3_words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busca_expandida(termo):\n",
    "    expansao = top_3_words_txt(termo)\n",
    "    expansao.append(termo)\n",
    "    doc_expandido = busca_tf(expansao)\n",
    "    return (expansao, doc_expandido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para imprimir os resultados das buscas expandidas e original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprime_buscas(termo):\n",
    "    expansao, doc_expandido = busca_expandida(termo)\n",
    "    busca_original = busca_tf([termo])\n",
    "    print(\"Termo: '\", termo, \"'\")\n",
    "    print(\"Expansao: \",expansao)\n",
    "    print(\"Busca expandida: \", len(doc_expandido))\n",
    "    print(\"Busca original: \", len(busca_original))\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expansão da busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termo: ' dilma '\n",
      "Expansao:  ['rousseff', 'disse', 'é', 'dilma']\n",
      "Busca expandida:  7397\n",
      "Busca original:  4270\n",
      " \n",
      "Termo: ' michel '\n",
      "Expansao:  ['temer', 'saliba', 'louis', 'michel']\n",
      "Busca expandida:  418\n",
      "Busca original:  334\n",
      " \n",
      "Termo: ' impeachment '\n",
      "Expansao:  ['presidente', 'dilma', 'fernando', 'impeachment']\n",
      "Busca expandida:  6141\n",
      "Busca original:  96\n",
      " \n",
      "Número de documentos na busca disjuntiva:  4361\n"
     ]
    }
   ],
   "source": [
    "imprime_buscas(\"dilma\")\n",
    "\n",
    "imprime_buscas(\"michel\")\n",
    "\n",
    "imprime_buscas(\"impeachment\")\n",
    "\n",
    "print(\"Número de documentos na busca disjuntiva: \", len(busca_or(\"dilma\", \"michel\", \"impeachment\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Quais os termos retornados para a expansão de cada consulta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"Dilma\":** rousseff; disse; é;\n",
    "\n",
    "**\"Michel\":** temer; saliba; louis;\n",
    "\n",
    "**\"Impeachment\":** presidente; dilma; fernando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Você acha que esses termos são de fato relacionados com a consulta original? Justifique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, pois as top-3 palavras que mais aparecem nas consultas estão relacionadas com o termo. Por exemplo, na busca por \"Dilma\" a palavra mais frequente é o seu sobrenome, \"Rousseff\"; o mesmo acontece na consulta por \"Impeachment\", onde são retornadas as palavras \"presidente\", \"Dilma\", e \"Fernando\", referenciando que os dois nomes citados, Dilma Rousseff e Fernando Color, estão ambos associados com \"impeachment\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acredito que a busca expandida melhor captura a necessidade de informação do usuário, pois ela retorna muito mais documentos do que a busa original. Além do mais, a busca expandida retorna os resultados que estão mais relacionados com o termo pesquisado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?\n",
    "<p>Recall (Revocação): é a fração de instâncias relevantes que são recuperadas.</p>\n",
    "<p>Precision (Precisão): é a fração de instâncias recuperadas que são relevantes</p>\n",
    "![Recall](https://wikimedia.org/api/rest_v1/media/math/render/svg/00783a9f77bb578eb51426da033d3cdc62cc0ea4)\n",
    "\n",
    "![Precision](https://wikimedia.org/api/rest_v1/media/math/render/svg/07edd83970d9cb357f76ba98166fe07cabc2d385)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais adequada para melhorar o recall, pois o número de documentos relevantes recuperados será maior, dado o número de documentos relevantes. Quanto maior a quantidade de documentos relevantes recuperados, maior será a quantidade de documentos relevantes contidos na busca. Entretanto, o precision será menor, já que ele é definido pela razão entre a quantidade de documentos relevantes na busca e a quantidade de documentos relevantes recuperados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
