{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperação da Informação e Busca na Web - 2018.1\n",
    "\n",
    "### Atividade: Lab 02 - Parte 1 - Expansão de Consultas\n",
    "### Aluno: Johanny de Lucena Santos\n",
    "\n",
    "## - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importações necessárias para a análise dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from unicodedata import normalize\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "from scipy import sparse\n",
    "from nltk import bigrams\n",
    "import scipy.sparse as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo download de biblioteca necessária para realizar a tokenização das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Definindo o arquivo com os dados a ser analisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/estadao_noticias_eleicao.csv', sep=',', encoding=\"utf-8\")\n",
    "\n",
    "#Substituindo linhas com valores NaN por string vazia, para não atrapalhar nas operações\n",
    "dataset = dataset.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para remover acentuação das palavras dos documentos\n",
    "Módulo **re** e **unicodedata** necessários para tratamento de expressões regulares e normalização de string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_acentuacao(palavra):\n",
    "    pattern = re.compile('[^a-zA-Z0-9 ]')\n",
    "    palavra = normalize('NFKD', palavra).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    return pattern.sub(' ', palavra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando junção dos títulos, subtítulos e conteúdos\n",
    "Na junção, está sendo removidos todos os acentos para facilitar a criação dos tokens dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documentos = dataset.titulo + \" \" + dataset.subTitulo + \" \" + dataset.conteudo\n",
    "documentos = documentos.apply(lambda palavra: remove_acentuacao(palavra).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix and Vocabulary construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação dos docIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docIDs = dataset.idNoticia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando os tokens dos dados e a frequência de termos de cada documento da lista de postings\n",
    "Utilizando a função **Count** da biblioteca **Collections** para realizar a contagem dos termos (frequência)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = documentos.apply(nltk.word_tokenize)\n",
    "tokens_list = documentos.apply(lambda text: text.lower().split())\n",
    "tokens2 = [token for tokens_list in tokens_list for token in tokens_list]\n",
    "termo_frequency = tokens.apply(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, vocab = co_occurrence_matrix(tokens2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consult bigram frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultable_matrix = matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def consult_frequency(w1, w2):\n",
    "    return (consultable_matrix[vocab[w1], vocab[w2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_3_words(termo):\n",
    "    ranking = []\n",
    "    for termo_matrix in consultable_matrix:\n",
    "        ranking.append(consult_frequency(termo, termo_matrix))\n",
    "    \n",
    "    return sorted(ranking, reverse=True)[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função geradora do índice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indiceInvertido = {}\n",
    "\n",
    "def gerarIndiceInvertido():\n",
    "    for i in range(len(tokens)):\n",
    "        idNoticia = docIDs[i]\n",
    "        palavras = tokens[i]\n",
    "    \n",
    "        for palavra in palavras:\n",
    "            if palavra not in indiceInvertido:\n",
    "                indiceInvertido[palavra.lower()] = {}\n",
    "        \n",
    "            if not indiceInvertido[palavra.lower()].get(idNoticia):\n",
    "                docs = indiceInvertido[palavra.lower()]\n",
    "                docs[idNoticia] = termo_frequency[i][palavra.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gerarIndiceInvertido()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função para retornar as palavras mais proximas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def busca_aproximada(termo, qtd):\n",
    "    termos = indiceInvertido.keys()\n",
    "    return sorted(termos, key=lambda palavra: nltk.edit_distance(termo.lower(),palavra))[0:qtd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo consult frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'poucos'\n",
    "w2 = 'recursos'\n",
    "consult_frequency(w1,w2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
